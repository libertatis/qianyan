{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# DuReader-Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/12/a827fac49f02eb642b9c0b7906e1684c24d87d866c6ccc9f40f76c41fc3e/paddlenlp-2.0.6-py3-none-any.whl (485kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 25kB/s eta 0:00:016\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (7.2.0)\n",
      "Installing collected packages: paddlenlp\n",
      "  Found existing installation: paddlenlp 2.0.1\n",
      "    Uninstalling paddlenlp-2.0.1:\n",
      "      Successfully uninstalled paddlenlp-2.0.1\n",
      "Successfully installed paddlenlp-2.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.io import BatchSampler\n",
    "from paddle.io import DataLoader\n",
    "from paddle.io import DistributedBatchSampler\n",
    "from paddlenlp.data import Dict\n",
    "from paddlenlp.data import Pad\n",
    "from paddlenlp.data import Stack\n",
    "from paddlenlp.data import Tuple\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.datasets import MapDataset\n",
    "from paddlenlp.ops.optimizer import AdamW\n",
    "from paddlenlp.transformers import BertTokenizer\n",
    "from paddlenlp.transformers import ErnieTokenizer\n",
    "from paddlenlp.transformers import ErnieGramTokenizer\n",
    "from paddlenlp.transformers import RobertaTokenizer\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "from models import BertForQuestionAnswering\n",
    "from models import ErnieForQuestionAnswering\n",
    "from models import ErnieGramForQuestionAnswering\n",
    "from models import RobertaForQuestionAnswering\n",
    "\n",
    "from config import Config\n",
    "from dataset import DuReaderChecklist\n",
    "\n",
    "from utils import compute_prediction_checklist\n",
    "from utils import CrossEntropyLossForChecklist\n",
    "from utils import evaluate\n",
    "from utils import predict\n",
    "from utils import prepare_train_features\n",
    "from utils import prepare_validation_features\n",
    "from utils import set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "MODEL_CLASSES = {\r\n",
    "    \"bert\": (BertForQuestionAnswering, BertTokenizer),\r\n",
    "    \"ernie\": (ErnieForQuestionAnswering, ErnieTokenizer),\r\n",
    "    \"ernie_gram\": (ErnieGramForQuestionAnswering, ErnieGramTokenizer),\r\n",
    "    \"roberta\": (RobertaForQuestionAnswering, RobertaTokenizer)\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_train(args):\r\n",
    "    \r\n",
    "    paddle.set_device(args.device)\r\n",
    "\r\n",
    "    args.model_type = args.model_type.lower()\r\n",
    "    model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\r\n",
    "    tokenizer = tokenizer_class.from_pretrained(args.model_name_or_path)\r\n",
    "\r\n",
    "    set_seed(args)\r\n",
    "    \r\n",
    "    assert args.train_file != None, \"--train_file should be set when training!\"\r\n",
    "    train_ds = DuReaderChecklist().read(args.train_file)\r\n",
    "    dev_ds = DuReaderChecklist().read(args.dev_file)\r\n",
    "\r\n",
    "    train_trans_func = partial(\r\n",
    "        prepare_train_features, \r\n",
    "        tokenizer=tokenizer,\r\n",
    "        args=args\r\n",
    "    )\r\n",
    "    train_ds.map(train_trans_func, batched=True)\r\n",
    "\r\n",
    "    dev_trans_func = partial(\r\n",
    "        prepare_validation_features, \r\n",
    "        tokenizer=tokenizer,\r\n",
    "        args=args\r\n",
    "    )\r\n",
    "    dev_ds.map(dev_trans_func, batched=True)\r\n",
    "\r\n",
    "    # 定义batchify_fn\r\n",
    "    train_batchify_fn = lambda samples, fn=Dict({\r\n",
    "        \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\r\n",
    "        \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\r\n",
    "        \"start_positions\": Stack(dtype=\"int64\"),\r\n",
    "        \"end_positions\": Stack(dtype=\"int64\"),\r\n",
    "        \"answerable_label\": Stack(dtype=\"int64\")\r\n",
    "    }): fn(samples)\r\n",
    "\r\n",
    "    dev_batchify_fn = lambda samples, fn=Dict({\r\n",
    "        \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\r\n",
    "        \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\r\n",
    "    }): fn(samples)\r\n",
    "\r\n",
    "    # 定义BatchSampler\r\n",
    "    train_batch_sampler = DistributedBatchSampler(\r\n",
    "        dataset=train_ds, \r\n",
    "        batch_size=args.batch_size, \r\n",
    "        shuffle=True\r\n",
    "    )\r\n",
    "    dev_batch_sampler = BatchSampler(\r\n",
    "        dataset=dev_ds, \r\n",
    "        batch_size=args.batch_size, \r\n",
    "        shuffle=False\r\n",
    "    )\r\n",
    "\r\n",
    "    # 构造DataLoader\r\n",
    "    train_data_loader = DataLoader(\r\n",
    "        dataset=train_ds,\r\n",
    "        batch_sampler=train_batch_sampler,\r\n",
    "        collate_fn=train_batchify_fn,\r\n",
    "        return_list=True\r\n",
    "    )\r\n",
    "\r\n",
    "    dev_data_loader =  DataLoader(\r\n",
    "        dataset=dev_ds,\r\n",
    "        batch_sampler=dev_batch_sampler,\r\n",
    "        collate_fn=dev_batchify_fn,\r\n",
    "        return_list=True\r\n",
    "    )\r\n",
    "\r\n",
    "    output_dir = os.path.join(args.output_dir, 'best_model')\r\n",
    "    if not os.path.exists(output_dir):\r\n",
    "        os.makedirs(output_dir)\r\n",
    "\r\n",
    "    model = model_class.from_pretrained(args.model_name_or_path)\r\n",
    "    # model = model_class.from_pretrained(output_dir)\r\n",
    "\r\n",
    "    num_training_steps = args.max_steps if args.max_steps > 0 else len(\r\n",
    "        train_data_loader) * args.num_train_epochs\r\n",
    "    num_train_epochs = math.ceil(num_training_steps / len(train_data_loader))\r\n",
    "\r\n",
    "    num_batches = len(train_data_loader)\r\n",
    "\r\n",
    "    lr_scheduler = LinearDecayWithWarmup(\r\n",
    "        learning_rate=args.learning_rate, \r\n",
    "        total_steps=num_training_steps,\r\n",
    "        warmup=args.warmup_proportion\r\n",
    "    )\r\n",
    "\r\n",
    "    # Generate parameter names needed to perform weight decay.\r\n",
    "    # All bias and LayerNorm parameters are excluded.\r\n",
    "    decay_params = [\r\n",
    "        p.name for n, p in model.named_parameters()\r\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "    ]\r\n",
    "    optimizer = paddle.optimizer.AdamW(\r\n",
    "        learning_rate=lr_scheduler,\r\n",
    "        epsilon=args.adam_epsilon,\r\n",
    "        parameters=model.parameters(),\r\n",
    "        weight_decay=args.weight_decay,\r\n",
    "        apply_decay_param_fun=lambda x: x in decay_params\r\n",
    "    )\r\n",
    "\r\n",
    "    criterion = CrossEntropyLossForChecklist()\r\n",
    "\r\n",
    "    best_val_f1 = 0.0\r\n",
    "\r\n",
    "    global_step = 0\r\n",
    "    tic_train = time.time()\r\n",
    "    for epoch in range(1, num_train_epochs + 1):\r\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\r\n",
    "\r\n",
    "            global_step += 1\r\n",
    "            \r\n",
    "            input_ids, segment_ids, start_positions, end_positions, answerable_label = batch\r\n",
    "            logits = model(input_ids=input_ids, token_type_ids=segment_ids)\r\n",
    "            loss = criterion(logits, (start_positions, end_positions, answerable_label))\r\n",
    "\r\n",
    "            if global_step % args.logging_steps == 0 :\r\n",
    "                print(\r\n",
    "                    \"global step %d, epoch: %d, batch: %d/%d, loss: %.5f, speed: %.2f step/s, lr: %1.16e\"\r\n",
    "                    % (global_step, epoch, step, num_batches, loss,\r\n",
    "                    args.logging_steps / (time.time() - tic_train), lr_scheduler.get_lr()))\r\n",
    "                \r\n",
    "                tic_train = time.time()\r\n",
    "        \r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            lr_scheduler.step()\r\n",
    "            optimizer.clear_grad()\r\n",
    "\r\n",
    "            if global_step % args.save_steps == 0 or global_step == num_training_steps:\r\n",
    "                dev_em, dev_f1 = evaluate(model=model, data_loader=dev_data_loader, args=args)\r\n",
    "\r\n",
    "                print(\"global step: %d, eval dev Exact Mactch: %.5f, f1_score: %.5f\" % (global_step, dev_em, dev_f1))\r\n",
    "\r\n",
    "                if dev_f1 > best_val_f1:\r\n",
    "                    best_val_f1 = dev_f1\r\n",
    "\r\n",
    "                    print(\"save model at global step: %d, best eval f1_score: %.5f\" % (global_step, best_val_f1))\r\n",
    "\r\n",
    "                    model.save_pretrained(output_dir)\r\n",
    "                    tokenizer.save_pretrained(output_dir)\r\n",
    "\r\n",
    "                if global_step == num_training_steps:\r\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_predict(args):\r\n",
    "\r\n",
    "    paddle.set_device(args.device)\r\n",
    "\r\n",
    "    output_dir = os.path.join(args.output_dir, \"best_model\")\r\n",
    "\r\n",
    "    # 1. 加载测试集\r\n",
    "    test_ds = DuReaderChecklist().read(args.test_file)\r\n",
    "\r\n",
    "    model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\r\n",
    "    tokenizer = tokenizer_class.from_pretrained(output_dir)\r\n",
    "\r\n",
    "    # 2. 转化为 id\r\n",
    "    test_trans_func = partial(\r\n",
    "        prepare_validation_features, \r\n",
    "        tokenizer=tokenizer,\r\n",
    "        args=args\r\n",
    "    )\r\n",
    "    test_ds.map(test_trans_func, batched=True)\r\n",
    "\r\n",
    "    # test BatchSampler\r\n",
    "    test_batch_sampler = BatchSampler(\r\n",
    "        dataset=test_ds, \r\n",
    "        batch_size=args.batch_size, \r\n",
    "        shuffle=False\r\n",
    "    )\r\n",
    "\r\n",
    "    # test dataset features batchify\r\n",
    "    test_batchify_fn = lambda samples, fn=Dict({\r\n",
    "        \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\r\n",
    "        \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\r\n",
    "    }): fn(samples)\r\n",
    "\r\n",
    "    # test DataLoader\r\n",
    "    test_data_loader =  DataLoader(\r\n",
    "        dataset=test_ds,\r\n",
    "        batch_sampler=test_batch_sampler,\r\n",
    "        collate_fn=test_batchify_fn,\r\n",
    "        return_list=True\r\n",
    "    )\r\n",
    "\r\n",
    "    model = model_class.from_pretrained(output_dir)\r\n",
    "    \r\n",
    "    all_predictions = predict(model, test_data_loader, args)\r\n",
    "\r\n",
    "    # Can also write all_nbest_json and scores_diff_json files if needed\r\n",
    "    with open('prediction.json', \"w\", encoding='utf-8') as writer:\r\n",
    "        writer.write(\r\n",
    "            json.dumps(\r\n",
    "                all_predictions, ensure_ascii=False, indent=4) + \"\\n\")\r\n",
    "\r\n",
    "    count = 0\r\n",
    "    for example in test_data_loader.dataset.data:\r\n",
    "        count += 1\r\n",
    "        print()\r\n",
    "        print('问题：',example['question'])\r\n",
    "        print('原文：',''.join(example['context']))\r\n",
    "        print('答案：',all_predictions[example['id']])\r\n",
    "        if count >= 5:\r\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = Config(model_type='roberta', \r\n",
    "              model_name_or_path='roberta-wwm-ext-large',  # roberta-wwm-ext-large\r\n",
    "              output_dir='./outputs/dureader-checklist/',\r\n",
    "              train_file='./checklist_data/train.json',\r\n",
    "              dev_file='./checklist_data/dev.json',\r\n",
    "              test_file='./checklist_data/test.json',\r\n",
    "\r\n",
    "              max_seq_length=384,\r\n",
    "              batch_size=4, \r\n",
    "              learning_rate=5e-5,\r\n",
    "              num_train_epochs=10,\r\n",
    "              logging_steps=20,\r\n",
    "              save_steps=200,\r\n",
    "              warmup_proportion=0.1,\r\n",
    "              weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-25 07:01:35,350] [    INFO] - Found /home/aistudio/.paddlenlp/models/roberta-wwm-ext-large/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "do_train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_predict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
